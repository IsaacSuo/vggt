# VGGT Phongæ¸²æŸ“ç³»ç»Ÿ - é˜¶æ®µå››è¿›å±•æŠ¥å‘Š

---

## ğŸ“‹ æŠ¥å‘ŠåŸºæœ¬ä¿¡æ¯

| é¡¹ç›®åç§° | VGGT + Phong Rendering System |
|---------|-------------------------------|
| **æŠ¥å‘Šç‰ˆæœ¬** | Phase 4 Progress v1.0 |
| **æŠ¥å‘Šé˜¶æ®µ** | Phase 4 (NormalHead + æ•°æ®ç­–ç•¥) |
| **æŠ¥å‘Šç”Ÿæˆæ—¶é—´** | 2025-12-14 |
| **å½“å‰HEAD** | `290f1c9` |
| **å½“å‰åˆ†æ”¯** | `phong` |

---

## ğŸ¯ Phase 4 ç›®æ ‡ä¸è¿›å±•

### åŸå§‹ç›®æ ‡
1. âœ… é‡å‘½å PBR â†’ Phongï¼ˆå‘½åè§„èŒƒåŒ–ï¼‰
2. âœ… ä¿®å¤è®­ç»ƒæµç¨‹ bug
3. âœ… æ”¯æŒ HuggingFace é¢„è®­ç»ƒæƒé‡åŠ è½½
4. âœ… å®ç° NormalHeadï¼ˆç›´æ¥é¢„æµ‹æ³•çº¿ï¼‰
5. âœ… æ·»åŠ æ³•çº¿-æ·±åº¦ä¸€è‡´æ€§çº¦æŸ
6. âœ… å®ç°ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥
7. ğŸ”„ æ•°æ®é›†é›†æˆï¼ˆè¿›è¡Œä¸­ï¼‰

### è¾¾æˆæƒ…å†µ
**æ ¸å¿ƒåŠŸèƒ½ 100% å®Œæˆ** - NormalHead + ä¸¤é˜¶æ®µè®­ç»ƒå·²å®ç°å¹¶æµ‹è¯•é€šè¿‡

---

## ğŸ“Š ä»£ç å˜æ›´æ±‡æ€»

### Commit å†å²

| Commit | æè¿° | å˜æ›´æ–‡ä»¶æ•° |
|--------|------|-----------|
| `290f1c9` | Add NormalHead with depth consistency constraint | 4 |
| `af5ed26` | Support loading pretrained weights from HuggingFace | 1 |
| `fb63ba7` | Fix training pipeline bugs | 3 |
| `3ed3bf1` | [Phase 4] Add learnable lighting and Phong training infrastructure | 8 |

### æ–°å¢/ä¿®æ”¹æ–‡ä»¶

```
vggt/
â”œâ”€â”€ heads/
â”‚   â””â”€â”€ normal_head.py          [NEW] 223 lines - æ³•çº¿é¢„æµ‹å¤´
â”œâ”€â”€ models/
â”‚   â””â”€â”€ vggt.py                 [MOD] +15 lines - é›†æˆNormalHead

training/
â”œâ”€â”€ train_phong.py              [MOD] +80 lines - ä¸¤é˜¶æ®µè®­ç»ƒé€»è¾‘
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ phong_training_config.json [MOD] +5 lines - ä¸¤é˜¶æ®µé…ç½®
â””â”€â”€ rendering/
    â””â”€â”€ phong_loss.py           [MOD] +50 lines - æ³•çº¿ä¸€è‡´æ€§æŸå¤±
```

---

## ğŸ—ï¸ æ¶æ„å˜æ›´

### 1. NormalHead å®ç°

**è®¾è®¡å†³ç­–**: ç›´æ¥é¢„æµ‹æ³•çº¿ï¼Œè€Œéä»æ·±åº¦è®¡ç®—

**åŸå› **:
- æ·±åº¦å›¾å¯èƒ½ä¸å‡†ç¡®ï¼Œå¯¼è‡´æ³•çº¿è®¡ç®—é”™è¯¯
- ç›´æ¥é¢„æµ‹å¯ä»¥æ•è·é«˜é¢‘ç»†èŠ‚
- é€šè¿‡ä¸€è‡´æ€§çº¦æŸä¿æŒä¸æ·±åº¦çš„å‡ ä½•å…³ç³»

**æ¶æ„** (ä¸å…¶ä»–DPT Headä¸€è‡´):
```python
class NormalHead(nn.Module):
    """
    é¢„æµ‹è¡¨é¢æ³•çº¿çš„DPTå¤´
    è¾“å…¥: aggregated_tokens (B, S, N, D)
    è¾“å‡º: normals (B, S, H, W, 3) å•ä½æ³•çº¿
    """
    def __init__(self, dim_in=768, patch_size=14, features=256, ...):
        # 4ä¸ªReassembleå±‚ + 4ä¸ªFusionå±‚ + è¾“å‡ºå·ç§¯
        self.scratch.output_conv2 = nn.Sequential(
            nn.Conv2d(head_features, 32, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 3, 1, 1, 0),  # è¾“å‡º3é€šé“
        )

    def forward(self, ...):
        out = self._forward_impl(...)
        normals = F.normalize(out, p=2, dim=-1, eps=1e-6)  # å•ä½åŒ–
        return normals
```

**å‚æ•°é‡**: 32.65M (ä¸ depth_head, point_head, material_head ç›¸åŒ)

### 2. æ³•çº¿-æ·±åº¦ä¸€è‡´æ€§çº¦æŸ

**Loss è®¾è®¡**:
```python
def compute_normal_consistency_loss(self, predicted_normals, depth, depth_conf=None):
    """
    çº¦æŸé¢„æµ‹æ³•çº¿ä¸æ·±åº¦å¯¼å‡ºæ³•çº¿çš„ä¸€è‡´æ€§

    L_cons = 1 - cos(normal_pred, normal_from_depth)
    """
    # ä»æ·±åº¦è®¡ç®—æ³•çº¿ (Sobelæ¢¯åº¦)
    depth_normals = self.depth_to_normals(depth)

    # ä½™å¼¦è·ç¦»
    cosine_sim = (predicted_normals * depth_normals).sum(dim=-1)
    cosine_dist = 1.0 - cosine_sim

    # å¯é€‰ï¼šç”¨æ·±åº¦ç½®ä¿¡åº¦åŠ æƒ
    if depth_conf is not None:
        conf_weight = depth_conf / (depth_conf.mean() + 1e-6)
        cosine_dist = cosine_dist * conf_weight

    return cosine_dist.mean()
```

**ä½œç”¨**:
- å•å‘çº¦æŸï¼ˆå½“å‰ï¼‰: NormalHead å­¦ä¹ åŒ¹é… DepthHead è¾“å‡º
- åŒå‘çº¦æŸï¼ˆé˜¶æ®µäºŒï¼‰: è§£å†» DepthHead åï¼Œæ¸²æŸ“æ¢¯åº¦å¯ä»¥ä¿®æ­£æ·±åº¦

### 3. ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥

**é—®é¢˜**: ä¸€è‡´æ€§çº¦æŸæ˜¯å•å‘çš„ï¼Œå¦‚æœ depth_head å†»ç»“ï¼š
- NormalHead è¢«è¿«å­¦ä¹  DepthHead çš„å™ªå£°
- æ¸²æŸ“æ¢¯åº¦æ— æ³•ä¿®æ­£å‡ ä½•

**è§£å†³æ–¹æ¡ˆ**: ä¸¤é˜¶æ®µè®­ç»ƒ

| é˜¶æ®µ | Steps | depth_head | å­¦ä¹ ç‡ | ç›®çš„ |
|------|-------|-----------|--------|------|
| 1 (Warm-up) | 0-4999 | å†»ç»“ | - | Material/Light/Normal å…ˆå­¦åŸºç¡€ |
| 2 (Fine-tune) | 5000+ | è§£å†» | base_lr Ã— 0.1 | åŒå‘æ¢¯åº¦æµï¼Œç²¾ä¿®å‡ ä½• |

**å®ç°**:
```python
def _maybe_unfreeze_depth(self):
    """æ£€æŸ¥æ˜¯å¦åº”è¯¥è§£å†»depth_head"""
    two_stage_config = self.config.get('two_stage_training', {})

    if not two_stage_config.get('enabled', False):
        return

    unfreeze_step = two_stage_config.get('unfreeze_depth_at_step', 5000)

    if self.global_step >= unfreeze_step:
        self._unfreeze_depth_head()

def _unfreeze_depth_head(self):
    """è§£å†»depth_headï¼Œä½¿ç”¨æ›´å°çš„å­¦ä¹ ç‡"""
    depth_lr = base_lr * depth_lr_ratio  # 0.1x

    for param in self.model.depth_head.parameters():
        param.requires_grad = True

    # æ·»åŠ åˆ°optimizerï¼Œç‹¬ç«‹å­¦ä¹ ç‡
    self.optimizer.add_param_group({
        'params': list(self.model.depth_head.parameters()),
        'lr': depth_lr,
        'name': 'depth_head'
    })
```

**é…ç½®**:
```json
"two_stage_training": {
    "enabled": true,
    "unfreeze_depth_at_step": 5000,
    "depth_lr_ratio": 0.1
}
```

---

## ğŸ§ª æµ‹è¯•ç»“æœ

### NormalHead é›†æˆæµ‹è¯•

```
[PhongTrainer] material_head: 32.65M total, 32.65M trainable
[PhongTrainer] light_head: 1.18M total, 1.18M trainable
[PhongTrainer] normal_head: 32.65M total, 32.65M trainable

loss/loss_phong_normal_consistency: 0.000131
loss/loss_phong_total: 0.250118
[Main] Training completed!
```

### ä¸¤é˜¶æ®µè®­ç»ƒæµ‹è¯•

```
Step 1-3: depth_unfrozen=False, requires_grad=False  (é˜¶æ®µ1)
[Stage 2: Unfreeze depth_head] Unfrozen 32.65M params, LR=1e-05
Step 4-6: depth_unfrozen=True, requires_grad=True    (é˜¶æ®µ2)

Optimizer param groups:
  Group 0 (default): lr=1.00e-04   <- material, light, normal
  Group 1 (depth_head): lr=1.00e-05  <- depth (10x smaller)
```

### æ¨¡å‹å‚æ•°ç»Ÿè®¡

| ç»„ä»¶ | å‚æ•°é‡ | è®­ç»ƒçŠ¶æ€ |
|------|--------|---------|
| aggregator | 909.11M | å†»ç»“ |
| camera_head | 216.17M | å†»ç»“ |
| point_head | 32.65M | å†»ç»“ |
| depth_head | 32.65M | é˜¶æ®µ1å†»ç»“â†’é˜¶æ®µ2è§£å†» |
| track_head | 65.94M | å†»ç»“ |
| material_head | 32.65M | è®­ç»ƒ |
| light_head | 1.18M | è®­ç»ƒ |
| normal_head | 32.65M | è®­ç»ƒ |
| **æ€»è®¡** | **1.32B** | |

---

## ğŸ“ æ•°æ®é›†ç­–ç•¥

### ç›®æ ‡æ•°æ®é›†: OpenMaterial

**ç»“æ„**:
```
datasets/
â”œâ”€â”€ groundtruth/
â”‚   â””â”€â”€ {scene_id}/
â”‚       â””â”€â”€ clean_{scene_id}.ply      # GT Mesh
â”œâ”€â”€ openmaterial/
â”‚   â””â”€â”€ {scene_id}/
â”‚       â”œâ”€â”€ train/images/*.png        # RGBå›¾åƒ
â”‚       â”œâ”€â”€ test/images/*.png
â”‚       â”œâ”€â”€ mask/                     # ç‰©ä½“æ©ç 
â”‚       â”œâ”€â”€ transforms_train.json     # ç›¸æœºå‚æ•°
â”‚       â””â”€â”€ transforms_test.json
```

**æ•°æ®æ ¼å¼** (NeRF/Instant-NGP):
```json
{
    "fl_x": 2333.33, "fl_y": 2333.33,  // ç„¦è·
    "cx": 800, "cy": 600,              // ä¸»ç‚¹
    "w": 1600, "h": 1200,              // å›¾åƒå°ºå¯¸
    "frames": [
        {
            "file_path": "train/images/000.png",
            "transform_matrix": [[4x4]]  // camera-to-world (OpenGL)
        }
    ]
}
```

### è®­ç»ƒç­–ç•¥å†³ç­–

**é—®é¢˜**: å¯å¾®åˆ†æ¸²æŸ“æ˜¯ç—…æ€é—®é¢˜
```
I â‰ˆ G(Geometry) Ã— M(Material) Ã— L(Lighting)
```
ç»™å®šå›¾åƒ Iï¼Œæœ‰æ— æ•°ç§ G, M, L ç»„åˆã€‚

**æ–¹æ¡ˆå¯¹æ¯”**:

| æ–¹æ¡ˆ | æ·±åº¦æ¥æº | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|---------|------|------|
| A | VGGTé¢„æµ‹ | ç®€å• | æ·±åº¦å¯èƒ½ä¸å‡†ï¼Œæè´¨å­¦å |
| B | GT Meshæ¸²æŸ“ | å‡ ä½•å‡†ç¡® | éœ€è¦é¢„å¤„ç† |
| **A+Bæ··åˆ** | GTç›‘ç£VGGT | æœ€ä½³ | éœ€è¦é¢„å¤„ç† |

**æœ€ç»ˆå†³ç­–**: A+B æ··åˆç­–ç•¥

### GT å¼•å¯¼è®­ç»ƒæ¶æ„

```
Input: RGB
   â”‚
   â–¼
VGGT (DepthHead è§£å†»)
   â”‚
   â”œâ”€â”€â–º Pred_Depth â”€â”€â–º L_depth â—„â”€â”€ GT_Depth (ä»PLYæ¸²æŸ“)
   â”‚         â”‚
   â”‚         â–¼
   â”œâ”€â”€â–º Pred_Normal â”€â”€â–º L_cons â—„â”€â”€ Derived(Pred_Depth)
   â”‚         â”‚
   â”‚         â–¼
   â”‚    Material + Light
   â”‚         â”‚
   â”‚         â–¼
   â””â”€â”€â–º Phong Render â”€â”€â–º L_rgb â—„â”€â”€ Target RGB
```

**Loss ç»„åˆ**:
```python
L_total = L_rgb + Î»_depth * L_depth + Î»_cons * L_cons + Î»_smooth * L_smooth
```

**ä¼˜åŠ¿**:
1. **æ¶ˆé™¤æ­§ä¹‰**: L_depth å›ºå®šå‡ ä½•ï¼Œè¿«ä½¿ L_rgb ä¼˜åŒ–æè´¨/å…‰ç…§
2. **æå‡èƒ½åŠ›**: VGGT depth_head å­¦ä¹ å‡†ç¡®æ·±åº¦
3. **æ¨æ–­ç‹¬ç«‹**: è®­ç»ƒåå¯æ‰”æ‰ GT Mesh
4. **ç»†èŠ‚ä¿ç•™**: L_cons è®© NormalHead å­¦ä¹ é«˜é¢‘ç»†èŠ‚

---

## ğŸ“‹ å¾…å®æ–½ä»»åŠ¡

### ä¸‹ä¸€æ­¥å®æ–½è®¡åˆ’

| æ­¥éª¤ | ä»»åŠ¡ | é¢„ä¼°æ—¶é—´ | ä¼˜å…ˆçº§ |
|------|------|---------|--------|
| 1 | é¢„å¤„ç†è„šæœ¬: PLY â†’ æ·±åº¦å›¾ | 1h | P0 |
| 2 | OpenMaterialDataset ç±» | 2h | P0 |
| 3 | æ·»åŠ  L_depth ç›‘ç£æŸå¤± | 30min | P0 |
| 4 | ä¿®æ”¹è®­ç»ƒé…ç½® | 15min | P0 |
| 5 | ç«¯åˆ°ç«¯æµ‹è¯• | 1h | P0 |

### é¢„å¤„ç†è„šæœ¬éœ€æ±‚

```python
# scripts/render_depth_from_mesh.py

def render_depth(mesh_path, camera_params, output_dir):
    """
    ä»PLY meshæ¸²æŸ“æ·±åº¦å›¾

    Args:
        mesh_path: GT mesh è·¯å¾„
        camera_params: transforms.json ä¸­çš„ç›¸æœºå‚æ•°
        output_dir: è¾“å‡ºæ·±åº¦å›¾ç›®å½•

    Output:
        æ¯å¸§å¯¹åº”çš„ depth_xxx.npy æˆ– depth_xxx.png
    """
    # ä½¿ç”¨ PyTorch3D æˆ– Trimesh + PyRender
```

### OpenMaterialDataset éœ€æ±‚

```python
class OpenMaterialDataset(BaseDataset):
    """
    OpenMaterial æ•°æ®é›†åŠ è½½å™¨

    è¾“å‡º:
        images: (S, 3, H, W)
        depths: (S, H, W)        # ä»PLYé¢„æ¸²æŸ“
        masks: (S, H, W)         # ç‰©ä½“æ©ç 
        extrinsics: (S, 3, 4)    # world-to-camera (OpenCV)
        intrinsics: (S, 3, 3)
    """
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### åæ ‡ç³»è½¬æ¢

**NeRF æ ¼å¼**: camera-to-world, OpenGL çº¦å®š
```
Y â†‘    Z (å)
  |   /
  |  /
  | /
  +------â†’ X
```

**VGGT æ ¼å¼**: world-to-camera, OpenCV çº¦å®š
```
      Z (å‰)
     /
    /
   +------â†’ X
   |
   â†“ Y
```

**è½¬æ¢æ­¥éª¤**:
1. OpenGL â†’ OpenCV: ç¿»è½¬ Y å’Œ Z
2. camera-to-world â†’ world-to-camera: æ±‚é€†

```python
def convert_nerf_to_opencv(c2w_opengl):
    """NeRF camera-to-world â†’ OpenCV world-to-camera"""
    # 1. OpenGL to OpenCV
    c2w_opencv = c2w_opengl.copy()
    c2w_opencv[:, 1:3] *= -1  # ç¿»è½¬ Y, Z

    # 2. camera-to-world to world-to-camera
    w2c_opencv = np.linalg.inv(c2w_opencv)

    return w2c_opencv[:3, :]  # è¿”å› 3x4
```

---

## ğŸ“ˆ æ€»ç»“

### é˜¶æ®µå››æˆæœ

| ç±»åˆ« | å†…å®¹ |
|------|------|
| **æ–°å¢ä»£ç ** | ~400 lines |
| **æ–°å¢æ¨¡å—** | NormalHead |
| **æ–°å¢åŠŸèƒ½** | æ³•çº¿é¢„æµ‹ã€ä¸€è‡´æ€§çº¦æŸã€ä¸¤é˜¶æ®µè®­ç»ƒ |
| **æ¶æ„æ”¹è¿›** | è§£è€¦å‡ ä½•ä¸æè´¨å­¦ä¹  |
| **ç­–ç•¥ç¡®å®š** | GTæ·±åº¦ç›‘ç£ + ä¸¤é˜¶æ®µè®­ç»ƒ |

### å½“å‰çŠ¶æ€

**âœ… æ ¸å¿ƒåŠŸèƒ½å®Œæˆ**:
- NormalHead å®ç°å¹¶é›†æˆ
- æ³•çº¿ä¸€è‡´æ€§çº¦æŸ
- ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥
- è®­ç»ƒæµç¨‹æµ‹è¯•é€šè¿‡

**ğŸ”„ è¿›è¡Œä¸­**:
- æ•°æ®é›†é›†æˆ
- GT æ·±åº¦æ¸²æŸ“é¢„å¤„ç†

### ä¸‹ä¸€æ­¥

1. å®ç°æ·±åº¦æ¸²æŸ“é¢„å¤„ç†è„šæœ¬
2. å®ç° OpenMaterialDataset
3. æ·»åŠ  L_depth ç›‘ç£æŸå¤±
4. ç«¯åˆ°ç«¯è®­ç»ƒæµ‹è¯•

---

**æŠ¥å‘Šå®Œæˆæ—¶é—´**: 2025-12-14
**å®¡æŸ¥äºº**: Claude Code (AI Assistant)
**çŠ¶æ€**: Phase 4 æ ¸å¿ƒåŠŸèƒ½å®Œæˆï¼Œæ•°æ®é›†é›†æˆè¿›è¡Œä¸­

---

**END OF PROGRESS REPORT**
