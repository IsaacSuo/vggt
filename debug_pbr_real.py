#!/usr/bin/env python3
"""
Debug script for PBR pipeline with PRETRAINED VGGT weights

è¿™ä¸ªè„šæœ¬çš„ç›®çš„:
1. åŠ è½½é¢„è®­ç»ƒçš„VGGTæ¨¡å‹ï¼ˆdepth/cameraæœ‰æƒé‡ï¼‰
2. MaterialHeadä¿æŒéšæœºåˆå§‹åŒ–
3. ç”¨çœŸå®å›¾åƒæµ‹è¯•ï¼ŒéªŒè¯å‡ ä½•è´¨é‡
4. æµ‹è¯•æ¢¯åº¦åå‘ä¼ æ’­

å…³é”®éªŒè¯ç‚¹:
- âœ“ æ·±åº¦é¢„æµ‹åº”è¯¥æ¸…æ™°åˆç†ï¼ˆæ¥è‡ªé¢„è®­ç»ƒæƒé‡ï¼‰
- âœ“ æ³•çº¿è®¡ç®—åº”è¯¥æ­£ç¡®ï¼ˆæ¥è‡ªæ·±åº¦ï¼‰
- âœ“ æè´¨é¢„æµ‹æ˜¯éšæœºçš„ï¼ˆMaterialHeadæœªè®­ç»ƒï¼‰
- âœ“ æ¸²æŸ“æµç¨‹å®Œæ•´ï¼ˆPhongç€è‰²ï¼‰
- âœ“ æ¢¯åº¦èƒ½ä¼ åˆ°MaterialHeadï¼ˆå¯è®­ç»ƒæ€§ï¼‰

è¿è¡Œæ–¹å¼:
    python debug_pbr_real.py
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__)))

import torch
import numpy as np
import matplotlib.pyplot as plt

print("=" * 80)
print("PBR Pipeline with Pretrained VGGT - Real Image Test")
print("=" * 80)

# ===== 1. ç”Ÿæˆæµ‹è¯•å›¾åƒ =====
print("\n[1/7] Generating test image...")

def generate_test_image(size=(518, 518)):
    """
    ç”Ÿæˆä¸€ä¸ªå¸¦æœ‰å‡ ä½•ç»“æ„çš„æµ‹è¯•å›¾åƒ
    è¿™æ ·é¢„è®­ç»ƒçš„depth headèƒ½é¢„æµ‹å‡ºåˆç†çš„æ·±åº¦
    """
    H, W = size
    img = np.zeros((H, W, 3), dtype=np.uint8)

    # åˆ›å»ºä¸€ä¸ªçº¢è‰²çš„çƒä½“ï¼ˆä¸­å¿ƒæ·±åº¦å¤§ï¼Œè¾¹ç¼˜æ·±åº¦å°ï¼‰
    y, x = np.ogrid[:H, :W]
    center = (H // 2, W // 2)
    radius = min(H, W) // 3

    # çƒä½“mask
    dist_from_center = np.sqrt((x - center[1])**2 + (y - center[0])**2)
    sphere_mask = dist_from_center <= radius

    # çƒä½“ç€è‰²ï¼ˆå¸¦ä¸€ç‚¹æ¸å˜ï¼Œæ¨¡æ‹Ÿå…‰ç…§ï¼‰
    img[sphere_mask] = [200, 50, 50]  # çº¢è‰²åŸºè°ƒ

    # æ·»åŠ é«˜å…‰åŒºåŸŸï¼ˆå·¦ä¸Šè§’ï¼‰
    highlight_mask = sphere_mask & (x < center[1]) & (y < center[0])
    img[highlight_mask] = [255, 100, 100]

    # æ·»åŠ èƒŒæ™¯ï¼ˆæµ…ç°è‰²ï¼‰
    img[~sphere_mask] = [230, 230, 230]

    return img

test_img = generate_test_image()
print(f"  Generated test image: {test_img.shape}, range: [{test_img.min()}, {test_img.max()}]")

# è½¬æ¢ä¸ºtensor
images = torch.from_numpy(test_img).float() / 255.0  # [0, 1]
images = images.permute(2, 0, 1).unsqueeze(0).unsqueeze(0)  # (1, 1, 3, H, W)
images = images.cuda()

print(f"  Tensor shape: {images.shape}")

# ===== 2. åˆå§‹åŒ–æ¨¡å‹ï¼ˆå¯ç”¨MaterialHeadï¼‰=====
print("\n[2/7] Initializing VGGT with MaterialHead...")

from vggt.models.vggt import VGGT

model = VGGT(
    enable_camera=True,
    enable_depth=True,
    enable_point=False,
    enable_track=False,
    enable_material=True,  # å…³é”®ï¼šå¯ç”¨æè´¨é¢„æµ‹
).cuda()

print(f"  Model initialized")
print(f"  MaterialHead parameters: {sum(p.numel() for p in model.material_head.parameters()) / 1e6:.2f}M")

# ===== 3. åŠ è½½é¢„è®­ç»ƒæƒé‡ =====
print("\n[3/7] Loading pretrained weights...")

try:
    # æ–¹æ³•1: ä»Hugging FaceåŠ è½½
    print("  Attempting to load from Hugging Face (facebook/VGGT-1B)...")
    from vggt.models.vggt import VGGT as VGGT_Pretrained
    pretrained_model = VGGT_Pretrained.from_pretrained("facebook/VGGT-1B")

    # æå–é¢„è®­ç»ƒæƒé‡
    pretrained_dict = pretrained_model.state_dict()

    # å½“å‰æ¨¡å‹çš„state_dict
    model_dict = model.state_dict()

    # è¿‡æ»¤æ‰MaterialHeadçš„keysï¼ˆå› ä¸ºé¢„è®­ç»ƒæ¨¡å‹æ²¡æœ‰ï¼‰
    pretrained_dict_filtered = {
        k: v for k, v in pretrained_dict.items()
        if k in model_dict and 'material_head' not in k
    }

    # æ›´æ–°æƒé‡
    model_dict.update(pretrained_dict_filtered)
    missing_keys, unexpected_keys = model.load_state_dict(model_dict, strict=False)

    print(f"  âœ… Loaded pretrained weights from Hugging Face")
    print(f"  Missing keys: {len(missing_keys)} (Expected: MaterialHead parameters)")
    print(f"  Unexpected keys: {len(unexpected_keys)}")

    # éªŒè¯MaterialHeadçš„keysåœ¨missingä¸­
    material_keys = [k for k in missing_keys if 'material_head' in k]
    print(f"  MaterialHead keys (randomly initialized): {len(material_keys)}")

except Exception as e:
    print(f"  âš ï¸  Could not load pretrained weights: {e}")
    print(f"  âš ï¸  Continuing with random initialization for all modules")
    print(f"  âš ï¸  Depth predictions will be poor (random), but pipeline will still work")

# ===== 4. åˆå§‹åŒ–æ¸²æŸ“å™¨ =====
print("\n[4/7] Initializing Phong Renderer...")

from training.rendering.phong_renderer import SimplePhongRenderer

renderer = SimplePhongRenderer().cuda()
print("  âœ… Renderer initialized")

# ===== 5. å‰å‘ä¼ æ’­ =====
print("\n[5/7] Running forward pass...")

model.eval()  # è¯„ä¼°æ¨¡å¼

with torch.no_grad():
    with torch.cuda.amp.autocast(enabled=True, dtype=torch.bfloat16):
        # VGGTå‰å‘ä¼ æ’­
        predictions = model(images)

        print("  Predictions keys:", list(predictions.keys()))

        # æå–æ·±åº¦
        depth = predictions['depth']  # (B, S, H, W, 1)
        print(f"  Depth shape: {depth.shape}, range: [{depth.min():.3f}, {depth.max():.3f}]")

        # æå–æè´¨
        materials_raw = {
            'diffuse': predictions['diffuse'],      # (B, S, 3, H, W)
            'specular': predictions['specular'],
            'roughness': predictions['roughness'],  # (B, S, 1, H, W)
            'ambient_occlusion': predictions['ambient_occlusion'],
        }

        print(f"  Diffuse range: [{materials_raw['diffuse'].min():.3f}, {materials_raw['diffuse'].max():.3f}]")
        print(f"  Roughness range: [{materials_raw['roughness'].min():.3f}, {materials_raw['roughness'].max():.3f}]")

        # è½¬æ¢æ ¼å¼: (B,S,C,H,W) â†’ (B,S,H,W,C) for renderer
        materials_for_render = {
            'diffuse': materials_raw['diffuse'].permute(0, 1, 3, 4, 2),
            'specular': materials_raw['specular'].permute(0, 1, 3, 4, 2),
            'roughness': materials_raw['roughness'].permute(0, 1, 3, 4, 2),
            'ambient_occlusion': materials_raw['ambient_occlusion'].permute(0, 1, 3, 4, 2),
        }

        # æ¸²æŸ“
        depth_for_render = depth.squeeze(-1)  # (B, S, H, W, 1) â†’ (B, S, H, W)
        rendered_img, normals = renderer(
            depth=depth_for_render,
            materials=materials_for_render,
            intrinsics=None,  # ä½¿ç”¨é»˜è®¤ç›¸æœº
        )

        print(f"  Rendered image shape: {rendered_img.shape}")
        print(f"  Rendered range: [{rendered_img.min():.3f}, {rendered_img.max():.3f}]")
        print(f"  Normals range: [{normals.min():.3f}, {normals.max():.3f}]")

print("  âœ… Forward pass successful")

# ===== 6. å¯è§†åŒ– =====
print("\n[6/7] Generating visualization...")

fig, axes = plt.subplots(2, 4, figsize=(20, 10))
fig.suptitle('PBR Pipeline with Pretrained VGGT Weights', fontsize=16, fontweight='bold')

b_idx, s_idx = 0, 0

# ç¬¬ä¸€è¡Œï¼šè¾“å…¥å’Œå‡ ä½•
# 1. è¾“å…¥å›¾åƒ
axes[0, 0].imshow(images[b_idx, s_idx].permute(1, 2, 0).cpu().numpy())
axes[0, 0].set_title('Input Test Image\n(Red sphere on gray bg)', fontsize=12)
axes[0, 0].axis('off')

# 2. æ·±åº¦å›¾ï¼ˆå½’ä¸€åŒ–æ˜¾ç¤ºï¼‰
depth_np = depth[b_idx, s_idx, :, :, 0].cpu().numpy()
d_min, d_max = depth_np.min(), depth_np.max()
depth_normalized = (depth_np - d_min) / (d_max - d_min + 1e-6)
im1 = axes[0, 1].imshow(depth_normalized, cmap='plasma')
axes[0, 1].set_title(f'Predicted Depth\n(Pretrained)\nrange:[{d_min:.2f},{d_max:.2f}]', fontsize=12)
axes[0, 1].axis('off')
plt.colorbar(im1, ax=axes[0, 1], fraction=0.046)

# 3. æ³•çº¿ï¼ˆå½’ä¸€åŒ–åˆ°[0,1]æ˜¾ç¤ºï¼‰
normals_np = normals[b_idx, s_idx].cpu().numpy()
normals_vis = (normals_np + 1.0) / 2.0
axes[0, 2].imshow(normals_vis)
axes[0, 2].set_title('Computed Normals\n(From depth gradient)\nShould show sphere curvature', fontsize=12)
axes[0, 2].axis('off')

# 4. æ·±åº¦çš„3Då¯è§†åŒ–ï¼ˆè½®å»“å›¾ï¼‰
axes[0, 3].contourf(depth_normalized, levels=10, cmap='viridis')
axes[0, 3].set_title('Depth Contour\n(Should show sphere shape)', fontsize=12)
axes[0, 3].axis('off')

# ç¬¬äºŒè¡Œï¼šæè´¨å’Œæ¸²æŸ“
# 5. Diffuse
diffuse_np = materials_for_render['diffuse'][b_idx, s_idx].cpu().numpy()
axes[1, 0].imshow(diffuse_np)
axes[1, 0].set_title(f'Predicted Diffuse\n(Random init)\nmean:{diffuse_np.mean():.3f}', fontsize=12)
axes[1, 0].axis('off')

# 6. Specular
specular_np = materials_for_render['specular'][b_idx, s_idx].cpu().numpy()
axes[1, 1].imshow(specular_np)
axes[1, 1].set_title(f'Predicted Specular\n(Random init)\nmean:{specular_np.mean():.3f}', fontsize=12)
axes[1, 1].axis('off')

# 7. Roughness
roughness_np = materials_for_render['roughness'][b_idx, s_idx, :, :, 0].cpu().numpy()
im2 = axes[1, 2].imshow(roughness_np, cmap='gray', vmin=0, vmax=1)
axes[1, 2].set_title(f'Predicted Roughness\n(Random init)\nmean:{roughness_np.mean():.3f}', fontsize=12)
axes[1, 2].axis('off')
plt.colorbar(im2, ax=axes[1, 2], fraction=0.046)

# 8. æœ€ç»ˆæ¸²æŸ“
rendered_np = rendered_img[b_idx, s_idx].cpu().numpy()
axes[1, 3].imshow(rendered_np)
axes[1, 3].set_title(f'PBR Rendered\n(DepthÃ—Material)\nrange:[{rendered_np.min():.2f},{rendered_np.max():.2f}]', fontsize=12)
axes[1, 3].axis('off')

plt.tight_layout()
output_path = 'debug_pbr_real.png'
plt.savefig(output_path, dpi=150, bbox_inches='tight')
print(f"  âœ… Visualization saved to: {output_path}")

# ===== 7. æ¢¯åº¦æµ‹è¯• =====
print("\n[7/7] Testing gradient backpropagation...")

model.train()  # åˆ‡æ¢åˆ°è®­ç»ƒæ¨¡å¼

# å‡†å¤‡æŸå¤±å‡½æ•°
from training.rendering.pbr_loss import PBRLoss

loss_fn = PBRLoss(weight=1.0, photometric_loss_type='l1').cuda()

# è½¬æ¢ç›®æ ‡å›¾åƒæ ¼å¼: (B,S,C,H,W) â†’ (B,S,H,W,C)
target_img = images.permute(0, 1, 3, 4, 2)

# é‡æ–°å‰å‘ä¼ æ’­ï¼ˆéœ€è¦æ¢¯åº¦ï¼‰
with torch.cuda.amp.autocast(enabled=True, dtype=torch.bfloat16):
    predictions_train = model(images)

    depth_train = predictions_train['depth'].squeeze(-1)
    materials_train = {
        'diffuse': predictions_train['diffuse'].permute(0, 1, 3, 4, 2),
        'specular': predictions_train['specular'].permute(0, 1, 3, 4, 2),
        'roughness': predictions_train['roughness'].permute(0, 1, 3, 4, 2),
        'ambient_occlusion': predictions_train['ambient_occlusion'].permute(0, 1, 3, 4, 2),
    }

    rendered_train, _ = renderer(depth_train, materials_train)

    # è®¡ç®—æŸå¤±
    loss = loss_fn(rendered_train, target_img)

print(f"  Photometric loss: {loss.item():.6f}")

# åå‘ä¼ æ’­
print("  Running backward pass...")
loss.backward()

# æ£€æŸ¥MaterialHeadçš„æ¢¯åº¦
material_grad_found = False
max_grad_norm = 0.0
grad_params_count = 0

for name, param in model.material_head.named_parameters():
    if param.grad is not None:
        grad_norm = param.grad.norm().item()
        max_grad_norm = max(max_grad_norm, grad_norm)
        grad_params_count += 1

        if not material_grad_found:
            print(f"  âœ… Gradient detected in MaterialHead: {name}")
            print(f"     Gradient norm: {grad_norm:.6f}")
            material_grad_found = True

if material_grad_found:
    print(f"  âœ… SUCCESS: Gradients flow to MaterialHead!")
    print(f"  Total parameters with gradients: {grad_params_count}")
    print(f"  Max gradient norm: {max_grad_norm:.6f}")
else:
    print(f"  âŒ ERROR: No gradients detected in MaterialHead!")
    print(f"  This means the pipeline is broken for training.")

# ===== æ€»ç»“ =====
print("\n" + "=" * 80)
print("TEST COMPLETED!")
print("=" * 80)

print("\nğŸ“Š Results Summary:")
print(f"  âœ“ Forward pass: SUCCESS")
print(f"  âœ“ Depth prediction: range [{d_min:.3f}, {d_max:.3f}]")
print(f"  âœ“ Material prediction: Diffuse mean {diffuse_np.mean():.3f}")
print(f"  âœ“ Rendering: range [{rendered_np.min():.3f}, {rendered_np.max():.3f}]")
print(f"  âœ“ Gradient test: {'PASSED âœ…' if material_grad_found else 'FAILED âŒ'}")

print("\nğŸ” Visual Inspection Checklist:")
print("  Open debug_pbr_real.png and check:")
print("  1. Depth map shows a clear sphere shape (lighter in center, darker at edges)")
print("  2. Normals show purple/blue tones with curvature")
print("  3. Diffuse/Specular are random-ish (MaterialHead not trained)")
print("  4. Final render has some shading variations (Phong working)")

print("\nğŸš€ Next Steps:")
if material_grad_found:
    print("  âœ… Pipeline is ready for training!")
    print("  âœ… Proceed to Phase 4: Integrate into training loop")
else:
    print("  âŒ Fix gradient flow issues before training")
    print("  Check: amp settings, frozen modules, loss computation")

print("\n" + "=" * 80)
